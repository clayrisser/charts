apiVersion: integration.risserlabs.com/v1alpha2
kind: Socket
metadata:
  name: {{ template "velero.name" . }}-schedule-replicator
  labels:
    app.kubernetes.io/name: {{ template "velero.name" . }}
    helm.sh/chart: {{ .Chart.Name }}-{{ .Chart.Version }}
    app.kubernetes.io/instance: {{ .Release.Name }}
    app.kubernetes.io/managed-by: {{ .Release.Service }}
spec:
  epoch: {{ now | unixEpoch | quote }}
  interfaceVersions: '*'
  interface:
    name: replicator
    namespace: {{ .Release.Namespace }}
  resources:
    - when: [coupled, updated]
      do: recreate
      resource: |
        apiVersion: batch/v1
        kind: Job
        metadata:
          name: {{ template "velero.name" . }}-schedule-coupled-or-updated-{% .plug.metadata.namespace %}
        spec:
          activeDeadlineSeconds: 360
          backoffLimit: 6
          ttlSecondsAfterFinished: 360
          template:
            spec:
              restartPolicy: Never
              affinity:
                nodeAffinity:
                  requiredDuringSchedulingIgnoredDuringExecution:
                    nodeSelectorTerms:
                      - matchExpressions:
                          - key: kubernetes.io/arch
                            operator: In
                            values:
                              - amd64
              containers:
                - name: kubectl
                  image: bitnami/kubectl:1.20.9
                  command:
                    - sh
                    - -c
                    - |
                      cat <<EOF | kubectl delete -f -
                      apiVersion: velero.io/v1
                      kind: Schedule
                      metadata:
                        name: {% .plugConfig.name %}
                        namespace: {{ .Release.Namespace }}
                      EOF
                      cat <<EOF | kubectl get -f - -o yaml | grep -v '^\s*namespace:\s' | kubectl apply -f - --namespace={{ .Release.Namespace }}
                      apiVersion: velero.io/v1
                      kind: Schedule
                      metadata:
                        name: {% .plugConfig.name %}
                        namespace: {% .plug.metadata.namespace %}
                      EOF
                      kubectl get pods -n {{ .Release.Namespace }} \
                        -l job-name={{ template "velero.name" . }}-schedule-coupled-or-updated-{% .plug.metadata.namespace %} \
                        --field-selector status.phase=Failed \
                        -o yaml | kubectl delete -f -
    - when: [decoupled]
      do: recreate
      resource: |
        apiVersion: batch/v1
        kind: Job
        metadata:
          name: {{ template "velero.name" . }}-schedule-decoupled-{% .plug.metadata.namespace %}
        spec:
          activeDeadlineSeconds: 360
          backoffLimit: 6
          ttlSecondsAfterFinished: 360
          template:
            spec:
              restartPolicy: Never
              affinity:
                nodeAffinity:
                  requiredDuringSchedulingIgnoredDuringExecution:
                    nodeSelectorTerms:
                      - matchExpressions:
                          - key: kubernetes.io/arch
                            operator: In
                            values:
                              - amd64
              containers:
                - name: kubectl
                  image: bitnami/kubectl:1.20.9
                  command:
                    - sh
                    - -c
                    - |
                      cat <<EOF | kubectl delete -f -
                      apiVersion: velero.io/v1
                      kind: Schedule
                      metadata:
                        name: {% .plugConfig.name %}
                        namespace: {{ .Release.Namespace }}
                      EOF
                      kubectl get pods -n {{ .Release.Namespace }} \
                        -l job-name={{ template "velero.name" . }}-schedule-decoupled-{% .plug.metadata.namespace %} \
                        --field-selector status.phase=Failed \
                        -o yaml | kubectl delete -f -
